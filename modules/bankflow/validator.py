#!/usr/bin/env python3
"""
Bank Flow Validator Module - é“¶è¡Œæµæ°´æ ¡éªŒæ¨¡å—
æä¾›å®Œæ•´çš„æºæ–‡ä»¶ä¸ç›®æ ‡è¡¨æ•°æ®æ ¡éªŒåŠŸèƒ½
"""
import os
import sys
import re
import csv
import io
from datetime import datetime
from collections import defaultdict
from typing import Dict, List, Tuple, Optional, Callable

# æ·»åŠ é¡¹ç›®è·¯å¾„
sys.path.insert(0, os.path.dirname(os.path.dirname(__file__)))
from scripts.run_workflow_simulation import (
    get_token,
    list_files,
    download_raw,
    parse_csv,
    parse_xls,
    parse_xlsx,
    filter_latest_date_files,
    record_key,
    _amt_str,
    _extract_account_prefix,
    COMPANY_PROFILE_LOOKUP,
    APP_TOKEN,
    TABLE_ID,
    BASE,
    FIELD_MAP,
)


class ValidationResult:
    """æ ¡éªŒç»“æœç±»"""
    def __init__(self):
        self.total_source = 0
        self.total_target = 0
        self.matched = 0
        self.mismatched = 0
        self.source_only = 0
        self.target_only = 0
        self.differences = []
        self.file_stats = {}
        self.date_range = ""  # æœ¬æ¬¡åŒæ­¥æ—¶é—´èŒƒå›´ï¼Œå¦‚ "20260104 ~ 20260227"
        self.type_updates = []  # ç±»å‹æŒ‰è§„åˆ™æ›´æ–°ï¼ˆæºâ‰ ç›®æ ‡ï¼Œå±æ­£å¸¸ï¼‰
        self.is_valid = True
        self.errors = []
        # é‡‘é¢æ±‡æ€»ï¼ˆæ ¸å¿ƒæ ¡éªŒï¼‰
        self.src_exp_total = 0.0
        self.src_inc_total = 0.0
        self.tgt_exp_total = 0.0
        self.tgt_inc_total = 0.0
        # å»é‡æ£€æµ‹ï¼ˆä»…ä½œå‚è€ƒï¼Œä¸å½±å“ is_validï¼‰
        self.duplicate_count = 0
        self.duplicate_groups = []

    def to_dict(self):
        # æ ¸å¿ƒæ ¡éªŒï¼šè®°å½•æ•°ä¸€è‡´ + é‡‘é¢ç»Ÿè®¡ä¸€è‡´
        count_ok = self.total_source == self.total_target
        exp_ok = abs(getattr(self, 'src_exp_total', 0) - getattr(self, 'tgt_exp_total', 0)) < 0.01
        inc_ok = abs(getattr(self, 'src_inc_total', 0) - getattr(self, 'tgt_inc_total', 0)) < 0.01
        is_valid = count_ok and exp_ok and inc_ok
        return {
            'total_source': self.total_source,
            'total_target': self.total_target,
            'src_exp_total': getattr(self, 'src_exp_total', 0),
            'src_inc_total': getattr(self, 'src_inc_total', 0),
            'tgt_exp_total': getattr(self, 'tgt_exp_total', 0),
            'tgt_inc_total': getattr(self, 'tgt_inc_total', 0),
            'date_range': getattr(self, 'date_range', ''),
            'is_valid': is_valid,
            'duplicate_count': getattr(self, 'duplicate_count', 0),
            'duplicate_groups_count': len(getattr(self, 'duplicate_groups', [])),
            'duplicate_record_ids': [
                rid for _, rids in getattr(self, 'duplicate_groups', [])
                for rid in rids[1:]
            ],
            'differences_count': len(self.differences),
            'type_updates_count': len(getattr(self, 'type_updates', [])),
            'file_stats': getattr(self, 'file_stats', {}),
        }


class BankFlowValidator:
    """é“¶è¡Œæµæ°´æ ¡éªŒå™¨ï¼šæºæ–‡ä»¶ä¸ç›®æ ‡è¡¨é€è®°å½•ã€é€å­—æ®µæ¯”å¯¹ï¼Œç¡®ä¿ç›®æ ‡è®°å½•æ¥è‡ªæ­£ç¡®æºæ–‡ä»¶ä¸å­—æ®µ"""

    def __init__(self, token: Optional[str] = None):
        self.token = token or get_token()
        self.result = ValidationResult()
        self._target_cache = None
        self._source_cache = None

    def _fetch_target_records(self, use_cache: bool = True) -> List[Dict]:
        """è·å–ç›®æ ‡è¡¨æ‰€æœ‰è®°å½•"""
        if use_cache and self._target_cache is not None:
            return self._target_cache

        import requests
        all_rec = []
        pt = None

        while True:
            params = {"page_size": 500}
            if pt:
                params["page_token"] = pt

            r = requests.get(
                f"{BASE}/open-apis/bitable/v1/apps/{APP_TOKEN}/tables/{TABLE_ID}/records",
                params=params,
                headers={"Authorization": f"Bearer {self.token}"},
            )
            j = r.json()

            if j.get("code") != 0:
                self.result.errors.append(f"æŸ¥è¯¢ç›®æ ‡è¡¨å¤±è´¥: {j.get('msg')}")
                break

            items = j.get("data", {}).get("items", [])
            for it in items:
                f = it.get("fields", {})
                td = f.get("äº¤æ˜“æ—¥æœŸ")
                if isinstance(td, (int, float)):
                    try:
                        dt = datetime.fromtimestamp(td / 1000)
                        td = dt.strftime("%Y%m%d")
                    except Exception:
                        td = str(td)[:8]
                else:
                    td = re.sub(r"\D", "", str(td or ""))[:8]

                all_rec.append({
                    "record_id": it.get("record_id"),
                    "æ¥æº": str(f.get("æ¥æº", "") or ""),
                    "è´¦å·": str(f.get("æˆ‘æ–¹è´¦å·") or f.get("è´¦å·", "") or "").strip(),
                    "æˆ‘æ–¹è´¦æˆ·": str(f.get("æˆ‘æ–¹è´¦æˆ·") or f.get("è´¦æˆ·", "") or "").strip(),
                    "æˆ‘æ–¹è´¦å·": str(f.get("æˆ‘æ–¹è´¦å·") or f.get("è´¦å·", "") or "").strip(),
                    "å¯¹æ–¹è´¦æˆ·": str(f.get("å¯¹æ–¹è´¦æˆ·", "") or "").strip(),
                    "å¯¹æ–¹è´¦å·": str(f.get("å¯¹æ–¹è´¦å·", "") or "").strip(),
                    "äº¤æ˜“æ—¥": td,
                    "æ”¯å‡º": f.get("æ”¯å‡º"),
                    "æ”¶å…¥": f.get("æ”¶å…¥"),
                    "è´§å¸": str(f.get("è´§å¸", "") or "").strip(),
                    "ç±»å‹": str(f.get("ç±»å‹", "") or "").strip(),
                    "æ‘˜è¦": str(f.get("æ‘˜è¦", "") or ""),
                    "å¤‡æ³¨": str(f.get("å¤‡æ³¨", "") or ""),
                    "äº¤æ˜“æµæ°´å·": str(f.get("äº¤æ˜“æµæ°´å·", "") or "").strip(),
                })

            pt = j.get("data", {}).get("page_token")
            if not pt or not items:
                break

        if use_cache:
            self._target_cache = all_rec
        return all_rec

    def _fetch_source_records(self, use_cache: bool = True) -> Tuple[List[Dict], Dict]:
        """è·å–å¹¶è§£ææ‰€æœ‰æºæ–‡ä»¶è®°å½•"""
        if use_cache and self._source_cache is not None:
            return self._source_cache

        files = list_files(self.token)
        source_files = [f for f in files if (f.get("name") or "").lower().endswith((".csv", ".xls", ".xlsx"))]
        to_process = filter_latest_date_files(source_files)

        all_src_rows = []
        src_by_file = defaultdict(list)

        for f in to_process:
            name = f.get("name", "")
            ext = (name or "").split(".")[-1].lower()
            raw = download_raw(self.token, f.get("token"))
            if not raw:
                self.result.errors.append(f"ä¸‹è½½å¤±è´¥: {name}")
                continue

            if ext == "xls":
                rows = parse_xls(raw, name)
            elif ext == "xlsx":
                rows = parse_xlsx(raw, name)
            else:
                rows = parse_csv(raw, name)

            for r in rows:
                r["æ¥æºæ–‡ä»¶"] = name
                src_key = self._build_fingerprint(r, is_source=True)
                r["_fingerprint"] = src_key

            src_by_file[name] = rows
            all_src_rows.extend(rows)

        result = (all_src_rows, dict(src_by_file))
        if use_cache:
            self._source_cache = result
        return result

    def _build_fingerprint(self, row: Dict, is_source: bool = True) -> Tuple:
        """æ„å»ºè®°å½•æŒ‡çº¹ç”¨äºåŒ¹é…ã€‚æºä¸ç›®æ ‡å‡ä½¿ç”¨ company_profile çš„ æˆ‘æ–¹è´¦å·ï¼Œç¡®ä¿å¯æ­£ç¡®å¯¹åº”"""
        if is_source:
            æ¥æº = str(row.get("æ¥æºæ–‡ä»¶", ""))
            prefix = _extract_account_prefix(æ¥æº)
            _, æˆ‘æ–¹è´¦å· = COMPANY_PROFILE_LOOKUP.get(prefix, ("", str(row.get("è´¦å·", ""))[:30]))
            è´¦å· = (æˆ‘æ–¹è´¦å· or str(row.get("è´¦å·", "")))[:30]
            return (
                æ¥æº,
                è´¦å·,
                str(row.get("äº¤æ˜“æ—¥", "")),
                _amt_str(row.get("æ”¯å–")),
                _amt_str(row.get("æ”¶å…¥")),
                str(row.get("å¯¹æ–¹æˆ·å", ""))[:50]
            )
        else:
            return (
                str(row.get("æ¥æº", "")),
                str(row.get("è´¦å·", "") or row.get("æˆ‘æ–¹è´¦å·", ""))[:30],
                str(row.get("äº¤æ˜“æ—¥", "")),
                _amt_str(row.get("æ”¯å‡º")),
                _amt_str(row.get("æ”¶å…¥")),
                str(row.get("å¯¹æ–¹è´¦æˆ·", ""))[:50]
            )

    def _detect_duplicates(self, tgt_rows: List[Dict]):
        """æ£€æµ‹ç›®æ ‡è¡¨ä¸­ record_key é‡å¤çš„è®°å½•ï¼ˆä¸ sync çš„ record_key ä¸€è‡´ï¼‰"""
        from collections import Counter
        base_keys = []
        for r in tgt_rows:
            bk = (
                str(r.get("æ¥æº", "")),
                str(r.get("è´¦å·", "") or r.get("æˆ‘æ–¹è´¦å·", ""))[:30],
                str(r.get("äº¤æ˜“æ—¥", "")),
                _amt_str(r.get("æ”¯å‡º")),
                _amt_str(r.get("æ”¶å…¥")),
                str(r.get("å¯¹æ–¹è´¦æˆ·", ""))[:50],
            )
            base_keys.append((bk, r.get("record_id")))
        cnt = Counter(bk for bk, _ in base_keys)
        dup_groups = []
        seen = set()
        for bk, rid in base_keys:
            if cnt[bk] > 1 and bk not in seen:
                seen.add(bk)
                rids = [rid for b, rid in base_keys if b == bk]
                dup_groups.append((bk, rids))
        self.result.duplicate_groups = dup_groups
        self.result.duplicate_count = sum(len(rids) - 1 for _, rids in dup_groups)

    def _compare_single_record(self, src_row: Dict, tgt_row: Dict) -> Tuple[bool, List[Dict]]:
        """é€å­—æ®µæ¯”å¯¹å•æ¡è®°å½•ï¼Œè¿”å› (æ˜¯å¦åŒ¹é…, å·®å¼‚åˆ—è¡¨)"""
        differences = []
        source_name = src_row.get("æ¥æºæ–‡ä»¶", "")

        # 1. è´§å¸å­—æ®µ
        src_currency = str(src_row.get("å¸ç§", "") or "").strip()
        tgt_currency = str(tgt_row.get("è´§å¸", "") or "").strip()
        src_norm = self._normalize_currency(src_currency)
        tgt_norm = self._normalize_currency(tgt_currency)

        if src_norm != tgt_norm:
            differences.append({
                "å­—æ®µ": "è´§å¸",
                "æºå€¼": src_currency,
                "ç›®æ ‡å€¼": tgt_currency,
                "ä¸¥é‡ç¨‹åº¦": "é«˜" if "OCBC" in source_name or "USD" in source_name else "ä¸­"
            })

        # 2. æˆ‘æ–¹è´¦å·ï¼ˆæœŸæœ›å€¼æ¥è‡ª company_profileï¼Œéæºæ–‡ä»¶è§£æï¼‰
        prefix = _extract_account_prefix(source_name or src_row.get("æ¥æºæ–‡ä»¶", ""))
        expected_name, expected_account = COMPANY_PROFILE_LOOKUP.get(prefix, ("", ""))
        tgt_account = str(tgt_row.get("æˆ‘æ–¹è´¦å·") or tgt_row.get("è´¦å·", "") or "").strip()
        if expected_account and expected_account != tgt_account:
            differences.append({"å­—æ®µ": "æˆ‘æ–¹è´¦å·", "æºå€¼": expected_account, "ç›®æ ‡å€¼": tgt_account, "ä¸¥é‡ç¨‹åº¦": "é«˜"})

        # 3. æˆ‘æ–¹è´¦æˆ·ï¼ˆæœŸæœ›å€¼æ¥è‡ª company_profileï¼Œéæºæ–‡ä»¶è§£æï¼‰
        tgt_name = str(tgt_row.get("æˆ‘æ–¹è´¦æˆ·") or tgt_row.get("è´¦æˆ·", "") or "").strip()
        if expected_name and expected_name != tgt_name:
            differences.append({"å­—æ®µ": "æˆ‘æ–¹è´¦æˆ·", "æºå€¼": expected_name, "ç›®æ ‡å€¼": tgt_name, "ä¸¥é‡ç¨‹åº¦": "ä¸­"})

        # 4. å¯¹æ–¹æˆ·å
        src_cp = str(src_row.get("å¯¹æ–¹æˆ·å", "") or "").strip()
        tgt_cp = str(tgt_row.get("å¯¹æ–¹è´¦æˆ·", "") or "").strip()
        if src_cp != tgt_cp:
            differences.append({"å­—æ®µ": "å¯¹æ–¹è´¦æˆ·", "æºå€¼": src_cp, "ç›®æ ‡å€¼": tgt_cp, "ä¸¥é‡ç¨‹åº¦": "ä¸­"})

        # 5. å¯¹æ–¹è´¦å·
        src_cp_acc = str(src_row.get("å¯¹æ–¹è´¦å·", "") or "").strip()
        tgt_cp_acc = str(tgt_row.get("å¯¹æ–¹è´¦å·", "") or "").strip()
        if src_cp_acc != tgt_cp_acc:
            differences.append({"å­—æ®µ": "å¯¹æ–¹è´¦å·", "æºå€¼": src_cp_acc, "ç›®æ ‡å€¼": tgt_cp_acc, "ä¸¥é‡ç¨‹åº¦": "ä½"})

        # 6. æ—¥æœŸ
        src_date = str(src_row.get("äº¤æ˜“æ—¥", "") or "").strip()
        tgt_date = str(tgt_row.get("äº¤æ˜“æ—¥", "") or "").strip()
        if src_date != tgt_date:
            differences.append({"å­—æ®µ": "äº¤æ˜“æ—¥", "æºå€¼": src_date, "ç›®æ ‡å€¼": tgt_date, "ä¸¥é‡ç¨‹åº¦": "é«˜"})

        # 7. æ”¯å‡ºé‡‘é¢
        src_exp = _amt_str(src_row.get("æ”¯å–"))
        tgt_exp = _amt_str(tgt_row.get("æ”¯å‡º"))
        if src_exp != tgt_exp:
            differences.append({"å­—æ®µ": "æ”¯å‡º", "æºå€¼": src_row.get("æ”¯å–"), "ç›®æ ‡å€¼": tgt_row.get("æ”¯å‡º"), "ä¸¥é‡ç¨‹åº¦": "é«˜"})

        # 8. æ”¶å…¥é‡‘é¢
        src_inc = _amt_str(src_row.get("æ”¶å…¥"))
        tgt_inc = _amt_str(tgt_row.get("æ”¶å…¥"))
        if src_inc != tgt_inc:
            differences.append({"å­—æ®µ": "æ”¶å…¥", "æºå€¼": src_row.get("æ”¶å…¥"), "ç›®æ ‡å€¼": tgt_row.get("æ”¶å…¥"), "ä¸¥é‡ç¨‹åº¦": "é«˜"})

        # 9. æ‘˜è¦ï¼ˆç›®æ ‡è¡¨å¯èƒ½æ˜¯"å¯¹æ–¹æˆ·å | æ‘˜è¦"æ ¼å¼ï¼‰
        src_summary = str(src_row.get("æ‘˜è¦", "") or "").strip()
        tgt_summary = str(tgt_row.get("æ‘˜è¦", "") or "").strip()
        if src_summary and src_summary not in tgt_summary:
            differences.append({"å­—æ®µ": "æ‘˜è¦", "æºå€¼": src_summary[:50], "ç›®æ ‡å€¼": tgt_summary[:50], "ä¸¥é‡ç¨‹åº¦": "ä½"})

        # 10. å¤‡æ³¨
        src_remark = str(src_row.get("å¤‡æ³¨", "") or "").strip()
        tgt_remark = str(tgt_row.get("å¤‡æ³¨", "") or "").strip()
        if src_remark != tgt_remark:
            differences.append({"å­—æ®µ": "å¤‡æ³¨", "æºå€¼": src_remark[:50], "ç›®æ ‡å€¼": tgt_remark[:50], "ä¸¥é‡ç¨‹åº¦": "ä½"})

        # 11. äº¤æ˜“æµæ°´å·
        src_ref = str(src_row.get("äº¤æ˜“æµæ°´å·", "") or "").strip()
        tgt_ref = str(tgt_row.get("äº¤æ˜“æµæ°´å·", "") or "").strip()
        if src_ref != tgt_ref:
            differences.append({"å­—æ®µ": "äº¤æ˜“æµæ°´å·", "æºå€¼": src_ref, "ç›®æ ‡å€¼": tgt_ref, "ä¸¥é‡ç¨‹åº¦": "ä¸­"})

        # 12. ç±»å‹ï¼šåŒæ­¥æ—¶æŒ‰ type_classification è§„åˆ™é‡ç®—ï¼Œæºä¸ç›®æ ‡ä¸ä¸€è‡´å±æ­£å¸¸ï¼Œä¸è®¡å…¥å·®å¼‚
        src_type = str(src_row.get("äº¤æ˜“ç±»å‹", "") or "").strip()
        tgt_type = str(tgt_row.get("ç±»å‹", "") or "").strip()
        if src_type != tgt_type:
            differences.append({
                "å­—æ®µ": "ç±»å‹",
                "æºå€¼": src_type,
                "ç›®æ ‡å€¼": tgt_type,
                "ä¸¥é‡ç¨‹åº¦": "æ­£å¸¸",
                "æŒ‰è§„åˆ™æ›´æ–°": True,
            })

        # 13. æ¥æº
        src_source = str(src_row.get("æ¥æºæ–‡ä»¶", "") or "").strip()
        tgt_source = str(tgt_row.get("æ¥æº", "") or "").strip()
        if src_source != tgt_source:
            differences.append({"å­—æ®µ": "æ¥æº", "æºå€¼": src_source, "ç›®æ ‡å€¼": tgt_source, "ä¸¥é‡ç¨‹åº¦": "é«˜"})

        # ç±»å‹æŒ‰è§„åˆ™æ›´æ–°ä¸è®¡å…¥å·®å¼‚
        real_diffs = [d for d in differences if not d.get("æŒ‰è§„åˆ™æ›´æ–°")]
        return len(real_diffs) == 0, differences

    def _normalize_currency(self, val: str) -> str:
        """æ ‡å‡†åŒ–è´§å¸"""
        s = str(val or "").upper().replace(" ", "")
        if "USD" in s or "ç¾å…ƒ" in s or "DOLLAR" in s:
            return "USD"
        if "CNY" in s or "RMB" in s or "äººæ°‘å¸" in s or "å…ƒ" in s:
            return "RMB"
        return s

    def validate_detailed(self, verbose: bool = True) -> ValidationResult:
        """
        è¯¦ç»†æ ¡éªŒï¼šé€å­—æ®µæ¯”å¯¹æºæ–‡ä»¶å’Œç›®æ ‡è¡¨
        
        Args:
            verbose: æ˜¯å¦è¾“å‡ºè¯¦ç»†ä¿¡æ¯
            
        Returns:
            ValidationResult æ ¡éªŒç»“æœå¯¹è±¡
        """
        self.result = ValidationResult()

        # 1. è·å–æ•°æ®
        all_src_rows, src_by_file = self._fetch_source_records()
        tgt_rows = self._fetch_target_records()

        self.result.total_source = len(all_src_rows)
        self.result.total_target = len(tgt_rows)

        if verbose:
            print("=" * 100)
            print("ã€é“¶è¡Œæµæ°´æ•°æ®æ ¡éªŒ - é€å­—æ®µè¯¦ç»†æ¯”å¯¹ã€‘")
            print("=" * 100)
            print(f"\næºæ–‡ä»¶è®°å½•æ•°: {self.result.total_source}")
            print(f"ç›®æ ‡è¡¨è®°å½•æ•°: {self.result.total_target}")
            print(f"\næŒ‰æ–‡ä»¶ç»Ÿè®¡:")
            for name, rows in sorted(src_by_file.items()):
                print(f"  - {name}: {len(rows)} æ¡")

        # 2. å»ºç«‹ç´¢å¼•
        src_by_fp = defaultdict(list)
        for r in all_src_rows:
            src_by_fp[r["_fingerprint"]].append(r)

        tgt_by_fp = defaultdict(list)
        for r in tgt_rows:
            tgt_key = self._build_fingerprint(r, is_source=False)
            r["_fingerprint"] = tgt_key
            tgt_by_fp[tgt_key].append(r)

        # 2.5 å»é‡æ£€æµ‹ï¼šç›®æ ‡è¡¨ä¸­ record_key é‡å¤çš„è®°å½•
        self._detect_duplicates(tgt_rows)

        # 3. é€æ¡æ¯”å¯¹
        all_differences = []

        for fp, src_records in src_by_fp.items():
            tgt_records = tgt_by_fp.get(fp, [])

            for i, src_rec in enumerate(src_records):
                if i < len(tgt_records):
                    tgt_rec = tgt_records[i]
                    is_match, diffs = self._compare_single_record(src_rec, tgt_rec)

                    if is_match:
                        self.result.matched += 1
                        # è®°å½•ç±»å‹æŒ‰è§„åˆ™æ›´æ–°ï¼ˆæ­£å¸¸ï¼Œä¸è®¡å…¥å·®å¼‚ï¼‰
                        type_diffs = [d for d in diffs if d.get("æŒ‰è§„åˆ™æ›´æ–°")]
                        for d in type_diffs:
                            self.result.type_updates.append({
                                "æ¥æº": src_rec.get("æ¥æºæ–‡ä»¶"),
                                "æˆ‘æ–¹è´¦å·": src_rec.get("è´¦å·", "")[:20],
                                "æ—¥æœŸ": src_rec.get("äº¤æ˜“æ—¥"),
                                "æºç±»å‹": d.get("æºå€¼"),
                                "ç›®æ ‡ç±»å‹": d.get("ç›®æ ‡å€¼"),
                            })
                    else:
                        self.result.mismatched += 1
                        all_differences.append({
                            "æºæ–‡ä»¶": src_rec.get("æ¥æºæ–‡ä»¶"),
                            "æºè®°å½•": src_rec,
                            "ç›®æ ‡è®°å½•": tgt_rec,
                            "å·®å¼‚": diffs
                        })
                else:
                    self.result.source_only += 1

        # ç›®æ ‡è¡¨æœ‰ä½†æºæ–‡ä»¶æ— çš„è®°å½•
        for fp, tgt_records in tgt_by_fp.items():
            src_records = src_by_fp.get(fp, [])
            if len(tgt_records) > len(src_records):
                self.result.target_only += len(tgt_records) - len(src_records)

        self.result.differences = all_differences

        # 4. é‡‘é¢æ±‡æ€»ï¼ˆæ ¸å¿ƒæ ¡éªŒï¼‰
        for r in all_src_rows:
            try:
                self.result.src_exp_total += float(str(r.get("æ”¯å–") or "0").replace(",", ""))
            except (ValueError, TypeError):
                pass
            try:
                self.result.src_inc_total += float(str(r.get("æ”¶å…¥") or "0").replace(",", ""))
            except (ValueError, TypeError):
                pass
        for r in tgt_rows:
            try:
                self.result.tgt_exp_total += float(str(r.get("æ”¯å‡º") or "0").replace(",", ""))
            except (ValueError, TypeError):
                pass
            try:
                self.result.tgt_inc_total += float(str(r.get("æ”¶å…¥") or "0").replace(",", ""))
            except (ValueError, TypeError):
                pass

        # 5. æŒ‰æ–‡ä»¶ç»Ÿè®¡ï¼ˆç”¨äºè¾“å‡ºï¼‰
        self._compute_file_stats(src_by_fp, tgt_by_fp)

        # 5.5 æ ¸å¿ƒæ ¡éªŒç»“è®º
        count_ok = self.result.total_source == self.result.total_target
        exp_ok = abs(self.result.src_exp_total - self.result.tgt_exp_total) < 0.01
        inc_ok = abs(self.result.src_inc_total - self.result.tgt_inc_total) < 0.01
        self.result.is_valid = count_ok and exp_ok and inc_ok

        # 6. è®¡ç®—æœ¬æ¬¡åŒæ­¥æ—¶é—´èŒƒå›´ï¼ˆäº¤æ˜“æ—¥ min ~ maxï¼‰
        dates = []
        for r in all_src_rows:
            d = re.sub(r"\D", "", str(r.get("äº¤æ˜“æ—¥", "") or ""))[:8]
            if len(d) == 8:
                dates.append(d)
        if dates:
            dmin, dmax = min(dates), max(dates)
            # æ ¼å¼åŒ–ä¸º YYYY-MM-DD ä¾¿äºé˜…è¯»
            fmt = lambda d: f"{d[:4]}-{d[4:6]}-{d[6:8]}" if len(d) == 8 else d
            self.result.date_range = f"{fmt(dmin)} ~ {fmt(dmax)}"
        else:
            self.result.date_range = "-"

        # 7. è¾“å‡ºç»“æœ
        if verbose:
            self._print_detailed_result(src_by_fp, tgt_by_fp)

        return self.result

    def _compute_file_stats(self, src_by_fp: Dict, tgt_by_fp: Dict):
        """æŒ‰æ–‡ä»¶ç»Ÿè®¡è®°å½•æ•°ã€é‡‘é¢"""
        by_file = defaultdict(lambda: {"è®°å½•æ•°": 0, "æ”¯å‡º": 0.0, "æ”¶å…¥": 0.0, "åŒ¹é…": 0, "å·®å¼‚": 0})
        for fp, src_records in src_by_fp.items():
            fname = fp[0] if isinstance(fp, tuple) else str(fp)
            for r in src_records:
                by_file[fname]["è®°å½•æ•°"] += 1
                try:
                    by_file[fname]["æ”¯å‡º"] += float(str(r.get("æ”¯å–") or "0").replace(",", ""))
                except (ValueError, TypeError):
                    pass
                try:
                    by_file[fname]["æ”¶å…¥"] += float(str(r.get("æ”¶å…¥") or "0").replace(",", ""))
                except (ValueError, TypeError):
                    pass
            tgt_records = tgt_by_fp.get(fp, [])
            for i, src_rec in enumerate(src_records):
                if i < len(tgt_records):
                    is_match, _ = self._compare_single_record(src_rec, tgt_records[i])
                    if is_match:
                        by_file[fname]["åŒ¹é…"] += 1
                    else:
                        by_file[fname]["å·®å¼‚"] += 1
        self.result.file_stats = dict(by_file)

    def _print_detailed_result(self, src_by_fp: Dict, tgt_by_fp: Dict):
        """æ‰“å°è¯¦ç»†æ¯”å¯¹ç»“æœï¼Œæ ¸å¿ƒï¼šè®°å½•æ•°+é‡‘é¢ç»Ÿè®¡"""
        count_ok = self.result.total_source == self.result.total_target
        exp_ok = abs(self.result.src_exp_total - self.result.tgt_exp_total) < 0.01
        inc_ok = abs(self.result.src_inc_total - self.result.tgt_inc_total) < 0.01

        print("\n" + "=" * 100)
        print("ã€æ ¡éªŒç»“æœ - æ ¸å¿ƒã€‘")
        print("=" * 100)
        print(f"  è®°å½•æ•°: æº={self.result.total_source} vs ç›®æ ‡={self.result.total_target} {'âœ“' if count_ok else 'âœ—'}")
        print(f"  æ”¯å‡ºåˆè®¡: æº={self.result.src_exp_total:,.2f} vs ç›®æ ‡={self.result.tgt_exp_total:,.2f} {'âœ“' if exp_ok else 'âœ—'}")
        print(f"  æ”¶å…¥åˆè®¡: æº={self.result.src_inc_total:,.2f} vs ç›®æ ‡={self.result.tgt_inc_total:,.2f} {'âœ“' if inc_ok else 'âœ—'}")
        print(f"  æœ¬æ¬¡åŒæ­¥æ—¶é—´èŒƒå›´: {self.result.date_range}")
        print(f"\n  ï¼ˆå‚è€ƒï¼‰å®Œå…¨åŒ¹é…: {self.result.matched} | å­˜åœ¨å·®å¼‚: {self.result.mismatched} | ä»…æºæœ‰: {self.result.source_only} | ä»…ç›®æ ‡æœ‰: {self.result.target_only} | é‡å¤: {self.result.duplicate_count} æ¡")

        if self.result.type_updates:
            print("\n" + "=" * 100)
            print(f"ã€ç±»å‹æŒ‰è§„åˆ™æ›´æ–°ã€‘å…± {len(self.result.type_updates)} æ¡ï¼ˆåŒæ­¥æ—¶æŒ‰ type_classification é‡ç®—ï¼Œå±æ­£å¸¸ï¼‰")
            print("=" * 100)
            for i, t in enumerate(self.result.type_updates[:15], 1):
                print(f"  {i}. {t['æ¥æº']} | è´¦å·={t['æˆ‘æ–¹è´¦å·']}... | æ—¥æœŸ={t['æ—¥æœŸ']} | æºç±»å‹={t['æºç±»å‹']} -> ç›®æ ‡ç±»å‹={t['ç›®æ ‡ç±»å‹']}")
            if len(self.result.type_updates) > 15:
                print(f"  ... ç­‰å…± {len(self.result.type_updates)} æ¡")

        if self.result.duplicate_groups:
            print("\n" + "=" * 100)
            print("ã€é‡å¤è®°å½•è¯¦æƒ…ã€‘åŒä¸€ record_key å‡ºç°å¤šæ¬¡ï¼ˆæ¥æº+è´¦å·+æ—¥æœŸ+é‡‘é¢+å¯¹æ–¹æˆ·åï¼‰")
            print("=" * 100)
            for i, (bk, rids) in enumerate(self.result.duplicate_groups[:10], 1):
                æ¥æº, è´¦å·, æ—¥æœŸ, æ”¯å‡º, æ”¶å…¥, å¯¹æ–¹ = bk
                print(f"  {i}. æ¥æº={æ¥æº} | è´¦å·={è´¦å·[:20]}... | æ—¥æœŸ={æ—¥æœŸ} | æ”¯å‡º={æ”¯å‡º} æ”¶å…¥={æ”¶å…¥} | å¯¹æ–¹={å¯¹æ–¹[:20]}...")
                print(f"     é‡å¤ {len(rids)} æ¡ï¼Œrecord_id: {rids}")
            if len(self.result.duplicate_groups) > 10:
                print(f"  ... ç­‰å…± {len(self.result.duplicate_groups)} ç»„é‡å¤")

        # æŒ‰æ–‡ä»¶æ±‡æ€»ï¼šæ–‡ä»¶/è®°å½•/é‡‘é¢
        if self.result.file_stats:
            print("\n" + "=" * 100)
            print("ã€æŒ‰æ–‡ä»¶æ±‡æ€»ã€‘æ–‡ä»¶ | è®°å½•æ•° | æ”¯å‡º | æ”¶å…¥ | åŒ¹é… | å·®å¼‚")
            print("=" * 100)
            total_exp, total_inc = 0.0, 0.0
            for fname, st in sorted(self.result.file_stats.items()):
                exp, inc = st.get("æ”¯å‡º", 0), st.get("æ”¶å…¥", 0)
                total_exp += exp
                total_inc += inc
                print(f"  {fname[:50]:50} | {st.get('è®°å½•æ•°', 0):>6} | {exp:>12.2f} | {inc:>12.2f} | {st.get('åŒ¹é…', 0):>4} | {st.get('å·®å¼‚', 0):>4}")
            print(f"  {'åˆè®¡':50} | {self.result.total_source:>6} | {total_exp:>12.2f} | {total_inc:>12.2f} | {self.result.matched:>4} | {self.result.mismatched:>4}")

        if self.result.matched > 0:
            print("\n" + "=" * 100)
            print("ã€é€å­—æ®µåŒ¹é…è¯¦æƒ…ç¤ºä¾‹ï¼ˆå‰3æ¡ï¼‰ã€‘")
            print("=" * 100)

            shown = 0
            for fp, src_records in src_by_fp.items():
                tgt_records = tgt_by_fp.get(fp, [])
                for i, src_rec in enumerate(src_records):
                    if i < len(tgt_records):
                        tgt_rec = tgt_records[i]
                        is_match, _ = self._compare_single_record(src_rec, tgt_rec)
                        if is_match:
                            shown += 1
                            if shown <= 3:
                                print(f"\nã€åŒ¹é…è®°å½• {shown}ã€‘æ¥æº: {src_rec.get('æ¥æºæ–‡ä»¶')}")
                                print(f"  1. æ¥æº:       æº='{src_rec.get('æ¥æºæ–‡ä»¶')}' -> ç›®æ ‡='{tgt_rec.get('æ¥æº')}' âœ“")
                                print(f"  2. æˆ‘æ–¹è´¦å·:   æº='{src_rec.get('è´¦å·')}' -> ç›®æ ‡='{tgt_rec.get('æˆ‘æ–¹è´¦å·')}' âœ“")
                                print(f"  3. æˆ‘æ–¹è´¦æˆ·:   æº='{src_rec.get('è´¦æˆ·å')}' -> ç›®æ ‡='{tgt_rec.get('æˆ‘æ–¹è´¦æˆ·')}' âœ“")
                                print(f"  4. å¯¹æ–¹è´¦æˆ·:   æº='{src_rec.get('å¯¹æ–¹æˆ·å')}' -> ç›®æ ‡='{tgt_rec.get('å¯¹æ–¹è´¦æˆ·')}' âœ“")
                                print(f"  5. å¯¹æ–¹è´¦å·:   æº='{src_rec.get('å¯¹æ–¹è´¦å·')}' -> ç›®æ ‡='{tgt_rec.get('å¯¹æ–¹è´¦å·')}' âœ“")
                                print(f"  6. äº¤æ˜“æ—¥:     æº='{src_rec.get('äº¤æ˜“æ—¥')}' -> ç›®æ ‡='{tgt_rec.get('äº¤æ˜“æ—¥')}' âœ“")
                                print(f"  7. æ”¯å‡º:       æº='{src_rec.get('æ”¯å–')}' -> ç›®æ ‡='{tgt_rec.get('æ”¯å‡º')}' âœ“")
                                print(f"  8. æ”¶å…¥:       æº='{src_rec.get('æ”¶å…¥')}' -> ç›®æ ‡='{tgt_rec.get('æ”¶å…¥')}' âœ“")
                                print(f"  9. è´§å¸:       æº='{src_rec.get('å¸ç§')}' -> ç›®æ ‡='{tgt_rec.get('è´§å¸')}' âœ“")
                                print(f"  10. æ‘˜è¦:      æº='{src_rec.get('æ‘˜è¦')}' -> ç›®æ ‡='{tgt_rec.get('æ‘˜è¦')}' âœ“")
                                print(f"  11. å¤‡æ³¨:      æº='{src_rec.get('å¤‡æ³¨')}' -> ç›®æ ‡='{tgt_rec.get('å¤‡æ³¨')}' âœ“")
                                print(f"  12. äº¤æ˜“æµæ°´å·: æº='{src_rec.get('äº¤æ˜“æµæ°´å·')}' -> ç›®æ ‡='{tgt_rec.get('äº¤æ˜“æµæ°´å·')}' âœ“")
                                print(f"  13. ç±»å‹:      æº='{src_rec.get('äº¤æ˜“ç±»å‹')}' -> ç›®æ ‡='{tgt_rec.get('ç±»å‹')}' âœ“")
                if shown >= 3:
                    break

        if self.result.differences:
            print("\n" + "=" * 100)
            print(f"ã€å·®å¼‚è¯¦æƒ…ã€‘å…± {len(self.result.differences)} æ¡")
            print("=" * 100)

            for i, diff in enumerate(self.result.differences[:10], 1):
                src_rec = diff["æºè®°å½•"]
                print(f"\n  {i}. æ¥æº: {diff['æºæ–‡ä»¶']}")
                print(f"     æˆ‘æ–¹è´¦å·: {src_rec.get('è´¦å·', 'N/A')} | å¯¹æ–¹: {src_rec.get('å¯¹æ–¹æˆ·å', 'N/A')[:30]}")
                print(f"     æ—¥æœŸ: {src_rec.get('äº¤æ˜“æ—¥', 'N/A')} | æ”¯å‡º: {src_rec.get('æ”¯å–', 'N/A')} | æ”¶å…¥: {src_rec.get('æ”¶å…¥', 'N/A')}")
                print(f"     å·®å¼‚å­—æ®µ ({len(diff['å·®å¼‚'])} ä¸ª):")
                for d in diff["å·®å¼‚"]:
                    if d.get("æŒ‰è§„åˆ™æ›´æ–°"):
                        print(f"       â„¹ï¸ {d['å­—æ®µ']}: æº='{d['æºå€¼']}' -> ç›®æ ‡='{d['ç›®æ ‡å€¼']}'ï¼ˆæŒ‰è§„åˆ™æ›´æ–°ï¼Œæ­£å¸¸ï¼‰")
                    else:
                        marker = "ğŸ”´" if d.get("ä¸¥é‡ç¨‹åº¦") == "é«˜" else ("ğŸŸ¡" if d.get("ä¸¥é‡ç¨‹åº¦") == "ä¸­" else "ğŸŸ¢")
                        print(f"       {marker} {d['å­—æ®µ']}: æº='{d['æºå€¼']}' -> ç›®æ ‡='{d['ç›®æ ‡å€¼']}'")

        print("\n" + "=" * 100)
        if count_ok and exp_ok and inc_ok:
            print("âœ… æ ¡éªŒé€šè¿‡ï¼šè®°å½•æ•°ä¸€è‡´ã€æ”¯å‡º/æ”¶å…¥é‡‘é¢ç»Ÿè®¡ä¸€è‡´")
        else:
            reasons = []
            if not count_ok:
                reasons.append("è®°å½•æ•°ä¸ä¸€è‡´")
            if not exp_ok:
                reasons.append("æ”¯å‡ºåˆè®¡ä¸ä¸€è‡´")
            if not inc_ok:
                reasons.append("æ”¶å…¥åˆè®¡ä¸ä¸€è‡´")
            print(f"âš ï¸ æ ¡éªŒæœªé€šè¿‡ï¼š{', '.join(reasons)}")
        print("=" * 100)

def main():
    """å‘½ä»¤è¡Œå…¥å£ï¼šæºæ–‡ä»¶ä¸ç›®æ ‡è¡¨é€è®°å½•ã€é€å­—æ®µæ¯”å¯¹"""
    import argparse

    parser = argparse.ArgumentParser(description='é“¶è¡Œæµæ°´æ•°æ®æ ¡éªŒï¼šæºæ–‡ä»¶ä¸ç›®æ ‡è¡¨é€è®°å½•é€å­—æ®µæ¯”å¯¹')
    parser.add_argument('--quiet', '-q', action='store_true', help='é™é»˜æ¨¡å¼ï¼Œåªè¾“å‡ºç»“æœæ‘˜è¦')

    args = parser.parse_args()

    validator = BankFlowValidator()
    result = validator.validate_detailed(verbose=not args.quiet)

    # è¾“å‡ºJSONæ ¼å¼ç»“æœ
    import json
    print("\n" + "=" * 100)
    print("ã€æ ¡éªŒç»“æœæ‘˜è¦(JSON)ã€‘")
    print("=" * 100)
    print(json.dumps(result.to_dict(), ensure_ascii=False, indent=2))

    return 0 if result.is_valid else 1


if __name__ == "__main__":
    sys.exit(main())
